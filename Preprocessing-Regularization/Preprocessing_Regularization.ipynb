{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvhF4dpbstK5"
      },
      "source": [
        "###**Problem Description :-**\n",
        "Consider the case of Pune labs in India. As the number of cases of COVID-19 is rising day by day, the government decided to predict the number of cases that would be critical, so that they can provide more ventilators.\n",
        "\n",
        "As an Al/ML expert, your task is to predict whether a person would get critical or not. You are provided with the data of the cases like age, sex, travelled place, immunity level, fever frequency, breathing difficulty level and blood sugar. Help the government predict the number of critical cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MRXD3kyt3E2"
      },
      "source": [
        "**Finding weigth corresponding to different independent variables in data using gradient descent and cost function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGOI6M2lpCNv"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycaYqKe1k5cZ"
      },
      "source": [
        "X = np.genfromtxt(\"train_X_pr.csv\", delimiter=',', dtype=np.float64, skip_header=1)\n",
        "Y = np.genfromtxt(\"train_Y_pr.csv\", delimiter=',', dtype=np.float64)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzGj3euolIbG"
      },
      "source": [
        "def replace_null_values_with_mean(X):\n",
        "    col_mean = np.nanmean(X, axis=0)\n",
        "    inds = np.where(np.isnan(X))\n",
        "    X[inds] = np.take(col_mean, inds[1])\n",
        "    return X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZRYOTNUoMvO"
      },
      "source": [
        "def mean_normalize(X):\n",
        "    for i in range(len(X[0])):\n",
        "        column = X[:, i]\n",
        "        avg = np.mean(column, axis=0)\n",
        "        min = np.min(column,  axis=0)\n",
        "        max = np.max(column,  axis=0)\n",
        "        X[:, i] = (column-avg)/(max-min)\n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxm6Dh_IlLXd"
      },
      "source": [
        "def standardize(X):\n",
        "    for column_index in range(len(X[0])):\n",
        "        column = X[:, column_index]\n",
        "        mean = np.mean(column, axis=0)\n",
        "        std = np.std(column, axis=0)\n",
        "        X[:, column_index] = (column - mean) / std\n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acygVe6HoPh1"
      },
      "source": [
        "def min_max_normalize(X):\n",
        "    for column_index in range(len(X[0])):\n",
        "        column = X[:, column_index]\n",
        "        min = np.min(column, axis=0)\n",
        "        max = np.max(column, axis=0)\n",
        "        difference = max - min\n",
        "        X[:, column_index] = (column - min) / difference\n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr9oDLTQlLTP"
      },
      "source": [
        "\n",
        "def sigmoid(Z):\n",
        "    A = 1.0 / (1.0 + np.exp(-Z))\n",
        "    return A"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVi4gLMTlLQn"
      },
      "source": [
        "def compute_cost(X, Y, W, b, Lambda):\n",
        "    M = len(Y)\n",
        "    Z = np.dot(X, W.T) + b\n",
        "    A = sigmoid(Z)\n",
        "    cost = (-1/M) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A))\n",
        "    regularization_cost = (Lambda * np.sum(np.square(W))) / (2 * M)\n",
        "    return cost + regularization_cost"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Gxd6XNlLOQ"
      },
      "source": [
        "def compute_gradient_of_cost_function(X, Y, W, b):\n",
        "    Z = np.dot(X, W.T) + b\n",
        "    A = sigmoid(Z)\n",
        "    db = np.sum(A - Y)\n",
        "    dw = np.dot((A - Y).T, X)\n",
        "    return dw, db"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjp2sdMhlLL1"
      },
      "source": [
        "def Optimize_weights_using_gradient_descent(X, Y, learning_rate, Lambda):\n",
        "    m = len(Y)\n",
        "    Threshold_value = 0.0000001\n",
        "    prev_cost, b, i = 0, 0, 1\n",
        "    Y = Y.reshape(X.shape[0], 1)\n",
        "    W = np.zeros((1, X.shape[1]))\n",
        "    while True:\n",
        "        dw, db = compute_gradient_of_cost_function(X, Y, W, b)\n",
        "        W = W - (learning_rate * (dw + Lambda*W))/m\n",
        "        b = b - (learning_rate * db)/m\n",
        "        cost = compute_cost(X, Y, W, b, Lambda)\n",
        "        if abs(cost - prev_cost) < (Threshold_value):\n",
        "            break\n",
        "        prev_cost = cost\n",
        "        i += 1\n",
        "    return W, b"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sldW6NpTlLJd"
      },
      "source": [
        "def save_model(weights, weights_file_name):\n",
        "    with open(weights_file_name, 'a', newline='') as weight_file:\n",
        "        file_writer = csv.writer(weight_file, delimiter=\",\")\n",
        "        file_writer.writerows(weights)\n",
        "        weight_file.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwkhUpiplLGu"
      },
      "source": [
        "X = replace_null_values_with_mean(X)\n",
        "#with min max normalisation, accuracy = 0.599621118815286\n",
        "#X = min_max_normalize(X)\n",
        "#with standardization, accuracy = 0.6547185071844512\n",
        "#X = standardize(X)\n",
        "#with mean_normalize, accuracy = 0.6569682172544592\n",
        "#X = mean_normalize(X)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZZnL1F3sX7H"
      },
      "source": [
        "**Storing weight of the data given for further prediction :-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5g_vHSUlLBH",
        "outputId": "3d235bd3-96de-4613-c129-13363e93596d"
      },
      "source": [
        "weights, b_value = Optimize_weights_using_gradient_descent(X, Y, learning_rate=0.0001, Lambda=0.1)\n",
        "weights = np.insert(weights, 0, b_value, axis=1)\n",
        "weights[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.26853547,  1.83614455, -0.29501935,  0.00773004,  0.24506314,\n",
              "        0.11307014, -0.01845501, -0.50970885])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De0v1dA7lK-e"
      },
      "source": [
        "def predict_target_values(test_X, weights):\n",
        "    b = weights[0]\n",
        "    weights = weights[1:]\n",
        "    A = sigmoid(np.dot(test_X, weights) + b)\n",
        "    Y_prediction = np.where(A >= 0.5, 1, 0)\n",
        "    return Y_prediction"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM9ye7sslK7l"
      },
      "source": [
        "pred_Y = predict_target_values(X, weights[0])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWxgmhWivzfv"
      },
      "source": [
        "**Using f1 score to validata prediction :-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM1R0__fsL6C",
        "outputId": "1e77d2e2-17a6-4784-ad1a-a2857857e26f"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "weighted_f1_score = f1_score(Y, pred_Y, average = 'weighted')\n",
        "weighted_f1_score"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.797239313518419"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}